# Проект Killah и lil Pushkin: Роли, Обязанности и Сроки

**Продолжительность проекта:** 5 июня 2025 г. - 17 июля 2025 г. (6 недель)
**Текущая дата:** 6 июня 2025 г.

## 1. Роли и Обязанности в Команде

### 1.1. Команда LLM (Проект "lil Pushkin")

* **Полина (Руководитель ML / Swift-разработчик для интеграции LLM):**
  * Курирует всю разработку LLM, обучение и DPO-доработку.
  * Координирует поиск, подготовку и управление наборами данных.
  * Руководит исследованиями и внедрением LoRA-стратегий.
  * Участвует в интеграции LLM ("lil Pushkin") в приложение Killah на Swift, включая работу с ExecuTorch.
* **Кира (ML Инженер):**
  * Помогает с подготовкой и предварительной обработкой наборов данных для различных LoRA.
  * Участвует в обучении LoRA, специализации и DPO.
  * Фокусируется на оценке моделей и метриках, подборе примеров для обучения.
* **Макс (ML Инженер - Инфраструктура Обучения):**
  * Разрабатывает и поддерживает Python-инфраструктуру для обучения LLM.
  * Управляет хранением данных и версионированием для наборов данных и моделей.
  * Помогает с квантованием моделей.
* **Пользователь (Владислав) (Ведущий разработчик LLM-алгоритмов / Руководитель проекта):**
  * Разрабатывает основные алгоритмы обучения и DPO.
  * Руководит тестированием моделей на GPU и процессами параллелизации.
  * Осуществляет общий контроль над проектом LLM и распределяет задачи по обучению специфичных LoRA.
  * Участвует в разработке стратегии LLM и реализации PersonaPlugs runtime.

### 1.2. Команда Приложения (Проект "Killah")

* **Пользователь (Владислав) (Руководитель Swift / Архитектор / Ведущий разработчик):**
  * Курирует всю разработку приложения Killah.
  * Определяет архитектуру приложения и обеспечивает соблюдение принципов проектирования.
  * Руководит реализацией основных функций, включая управление данными (SwiftData, `.killah`), базовый текстовый редактор, импорт/экспорт.
* **Артур (Swift Разработчик):**
  * Реализует компоненты пользовательского интерфейса и логику приложения на Swift/SwiftUI/AppKit.
  * Фокусируется на функциях текстового редактора, системе каретки, управлении окнами.
* **Полина (Swift-разработчик для интеграции LLM / ML Lead):**
  * Реализует интеграцию "lil Pushkin" в приложение, включая взаимодействие с LLM через ExecuTorch, обработку ответов, отображение предложений.
* **Жанна (UI/UX Дизайнер / Менеджер по отчетности):**
  * Проектирует пользовательский интерфейс и пользовательский опыт для всех окон и взаимодействий приложения (на базе существующих наработок).
  * Готовит еженедельные отчеты для куратора проекта.
  * Создает визуальные ресурсы и обеспечивает соответствие "минималистичной и архаичной эстетике".
  * На финальном этапе: дизайн презентационных и рекламных материалов.

## 2. График Разработки LLM ("lil Pushkin") - Параллельная работа

(Задачи могут выполняться параллельно разными членами команды)

### Недели 1-2 (5 - 15 июня): Подготовка Данных, Основа Модели и Инфраструктура

*   **Полина, Кира:**
    *   Параллельный сбор и подготовка наборов данных:
        *   Высококачественные авторские корпуса (Project Gutenberg, EN/RU) для `Foundational_Persona_LoRA`.
        *   Мультимодальные аудио-текстовые наборы данных (LibriSpeech, Common Voice, Open STT, Russian Scripted Monologue) для `Audio_Persona_LoRA`.
        *   Наборы данных для конкретных задач (WikiText-103, OpenAssistant/Dolly 15k) для специализированных LoRA (например, продолжение, перефразирование) - начальный сбор.
        *   Кира: сбор и очистка EN/RU текстовых корпусов.
        *   Полина: сбор и подготовка аудио-текст датасетов (LibriSpeech, Common Voice, Open STT и др.).
    *   Продолжение обучения и доработка `Foundational_Persona_LoRA`.
    *   Начало обучения `Audio_Persona_LoRA`.
    *   Параллельное начало обучения специализированных LoRA.
*   **Макс:**
    *   Настройка и развертывание инфраструктуры хранения данных для всех типов корпусов.
    *   Начало разработки Python-скриптов для конвейера обучения.
*   **Пользователь (Владислав):**
    *   Настройка среды для разработки и тестирования LLM (Gemma 3 4B).
    *   Проектирование архитектуры алгоритмов обучения и DPO.
    *   Начало обучения `Foundational_Persona_LoRA` (контроль и первые итерации тестирования).
*   **Все вместе (LLM команда):** Обсуждение и финализация метрик для оценки качества моделей.
*   **Цели этапа:** Готовые к использованию основные наборы данных; базовая инфраструктура обучения; первая версия `Foundational_Persona_LoRA` проходит начальное тестирование.

### Недели 2-4 (16 июня - 29 июня): Обучение Базовых и Специализированных LoRA, WQRM, Тестирование

*   **Полина, Кира:**
    *   Продолжение обучения и доработка `Foundational_Persona_LoRA`.
    *   Начало обучения `Audio_Persona_LoRA` (интеграция аудиовозможностей).
    *   Параллельное начало обучения 1-2 приоритетных специализированных LoRA (например, `LoRA_Continue_Specialized`, `LoRA_Rephrase_Specialized`) на подготовленных данных.
    *   Разработка и валидация Модели Оценки Качества Текста (WQRM).
*   **Макс:**
    *   Поддержка и оптимизация инфраструктуры обучения.
    *   Реализация скриптов для автоматического запуска экспериментов и сбора результатов.
*   **Пользователь (Владислав):**
    *   Активное тестирование всех обучаемых LoRA на GPU, анализ результатов, корректировка параметров обучения.
    *   Разработка и реализация PersonaPlugs runtime (концепция и Python-часть, если применимо).
    *   Генерация пар предпочтений для DPO с использованием WQRM.
*   **Цели этапа:** Функциональные `Audio_Persona_LoRA` и первые версии специализированных LoRA; работающая WQRM; регулярное тестирование и сбор метрик.

### Недели 4-6 (30 июня - 17 июля): DPO-доработка, Квантование, Финальное Тестирование и Подготовка к Интеграции

*   **Полина, Кира:**
    *   Применение Прямой Оптимизации Предпочтений (DPO) к специализированным LoRA.
    *   Итеративная доработка LoRA на основе результатов DPO и расширенного тестирования.
*   **Макс:**
    *   Квантование (INT4) финальных версий LoRA.
    *   Подготовка моделей к экспорту для ExecuTorch.
*   **Пользователь (Владислав):**
    *   Финальное комплексное тестирование всех компонентов LLM.
    *   Контроль процесса квантования и подготовки к развертыванию.
    *   Документирование LLM системы.
*   **Полина (совместно с Владиславом):** Начало подготовки к интеграции ExecuTorch моделей в Swift-приложение.
*   **Цели этапа:** DPO-доработанные, квантованные и протестированные LoRA, готовые к интеграции; документация по LLM.

## 3. График Разработки Приложения ("Killah") - Фокус на Базовый Функционал

(Приоритет на основной функционал, сложные визуальные эффекты и анимации откладываются)

### Этап 1 (Недели 1-2: 5 - 15 июня): Основа Приложения, Редактор, Хранение

*   **Пользователь (Владислав):**
    *   Настройка Xcode проекта, определение архитектуры.
    *   Реализация базовых моделей данных (`Document`, `EditSnapshot`).
    *   Настройка SwiftData для хранения документов и базового версионирования.
    *   Реализация основных файловых операций (создание, сохранение, загрузка простого текста/базового `.killah`).
*   **Артур:**
    *   Реализация базового текстового редактора на `NSTextView`.
    *   Базовая панель инструментов (форматирование текста).
    *   Начальная реализация системы каретки (без сложной логики LLM).
*   **Жанна:**
    *   UI/UX дизайн для Окна Редактора и Окна Персональных Заметок (основные элементы).
    *   Подготовка первого еженедельного отчета.
*   **Полина:** Изучение Swift и архитектуры приложения для будущей интеграции LLM.

### Этап 2 (Недели 2-3: 16 - 29 июня): Интеграция LLM (Заглушки), Управление Документами

*   **Пользователь (Владислав):**
    *   Проектирование API для взаимодействия с LLM в приложении.
    *   Реализация Окна Персональных Заметок (отображение списка документов).
    *   Экспорт в `.txt`.
*   **Артур:**
    *   Интеграция заглушек для отображения предложений LLM и навигации по ним.
    *   Улучшение системы каретки, подготовка к отображению состояний LLM.
*   **Полина:**
    *   Начало работы над Swift-модулем для взаимодействия с LLM (загрузка модели-заглушки, отправка запросов-заглушек).
*   **Жанна:**
    *   Дизайн UI для отображения предложений LLM, окон ответов.
    *   Подготовка еженедельного отчета.

### Этап 3 (Недели 3-4: 23 июня - 6 июля): Базовая Интеграция LLM, Персонализация (Основа)

*   **Пользователь (Владислав):**
    *   Проектирование системы персонализации и структуры окна настроек.
    *   Базовая реализация сохранения/загрузки формата `.killah` с учетом истории (без UI для истории).
*   **Артур:**
    *   Отображение реальных (или тестовых от Полины) ответов LLM в UI.
    *   Базовая навигация по истории версий (если данные уже структурированы Владиславом).
*   **Полина:**
    *   Интеграция первой рабочей (возможно, еще не финальной) версии `lil Pushkin` через ExecuTorch (или мок-интерфейс, если модель не готова).
    *   Реализация получения и отображения текстовых предложений от LLM.
*   **Жанна:**
    *   Дизайн Окна Настроек (основные секции, включая персонализацию).
    *   Подготовка еженедельного отчета.

### Этап 4 (Недели 4-5: 30 июня - 13 июля): Голосовой Ввод (Основа), Доработка Функционала

*   **Пользователь (Владислав):**
    *   Интеграция базового захвата аудио.
    *   Проектирование взаимодействия голосового ввода с LLM.
    *   Реализация базовой системы обработки ошибок и уведомлений.
*   **Артур:**
    *   UI для базового голосового ввода (кнопки старт/стоп, индикация записи).
    *   Доработка UI текстового редактора и Окна Персональных Заметок.
*   **Полина:**
    *   Интеграция STT (если доступно) и передача транскрибированного текста в LLM.
    *   Обработка команд или диктовки через LLM (базовая логика).
*   **Жанна:**
    *   Дизайн элементов голосового ввода, визуализации аудио (если будет базовая).
    *   Подготовка еженедельного отчета.

### Этап 5 (Недели 5-6: 7 июля - 17 июля): Финальная Интеграция LLM, Полировка, Базовое Тестирование Приложения

*   **Пользователь (Владислав):**
    *   Завершение интеграции финальных версий LLM.
    *   Реализация индексации документов для PersonaPlugs.
    *   Общее тестирование приложения, оптимизация производительности (базовая).
*   **Артур:**
    *   Полировка UI, исправление багов.
    *   Реализация простого UI для истории версий (если применимо).
*   **Полина:**
    *   Финальная настройка взаимодействия с LLM, обработка всех режимов (автодополнение, перефразирование по выделению, голосовой ввод).
    *   Тестирование LLM-связанного функционала в приложении.
*   **Жанна:**
    *   Финальный обзор UI/UX.
    *   Подготовка финального отчета и презентационных материалов (начало).

## 4. Приложение Killah - Поэтапная Архитектура

**Принцип разработки:** модули нараст­ают друг друга по шагам.

### 4.1. Модель данных и список заметок

* Document.swift (Swift struct, Identifiable, ObservableObject)

```swift
struct Document: Identifiable {
    let id: UUID
    var content: String
    var fileURL: URL?
    var lastModified: Date
    func save() throws
    static func load(from url: URL) throws -> Document
}
```

* PersistenceController.swift (SwiftData)
  * `@Model class DocumentEntity { }`
  * `@Model class EditSnapshot { }`
  * `@Model class TextSegment { }`
  * ModelContainer для хранения и миграций

* PersonalNotesWindow.swift (SwiftUI)
  * `List<Document>` с разделением на персонализированные/обычные
  * DocumentManager: `loadAll()`, `createNew()`, `delete(_:)`, `export(format:)`

### 4.2. Базовый редактор и автодополнение

* ContentView.swift + InlineSuggestingTextView (NSViewRepresentable)
* CustomInlineNSTextView:
  * `committedText()`, `ghostText()`, `clearGhostText()`
* LLMEngine.swift:
  * `startEngine()`, `stopEngine()`
  * `generateSuggestion(prompt: String, tokenStream: (String)->Void, onComplete: (Result<String, Error>)->Void)`

### 4.3. Интеллектуальная каретка

* CaretState.swift

```swift
enum CaretState { case typing, listening, generating, suggesting }
```

* CaretViewModel.swift (ObservableObject)
  * `@Published var state: CaretState`
  * `@Published var suggestedText: String?`
  * `@Published var position: NSRange`
  * `func triggerAutocompletion()`
  * `func acceptSuggestion()`, `func rejectSuggestion()`

* IntelligentCaretView.swift (SwiftUI View)
  * Overlay над редактором: ghostText, suggestedText, audioWaveform

### 4.4. Голосовой ввод и STT

* AudioInputManager.swift (ObservableObject)
  * `@Published var isListening: Bool`
  * `@Published var audioData: Data`
  * `@Published var audioWaveform: [Float]`
  * `func startListening()`, `func stopListening() -> Data`

* STTService.swift
  * `func transcribe(_ audio: Data) async -> String`

* **Flow:**
  1. `startListening()` → `state = .listening` + визуализация
  2. `stopListening()` → аудиоданные → `STTService.transcribe` → транскрипт
  3. транскрипт → `LLMEngine.generateSuggestion(...)`

### 4.5. История версий

* EditSnapshot.swift

```swift
struct EditSnapshot: Identifiable {
    let id: UUID
    let timestamp: Date
    let contentSnapshot: Data  // NSAttributedString snapshot
    let prompt: String
    let response: String
}
```

* В CaretViewModel:
  * `func previousSnapshot()`
  * `func nextSnapshot()`
* Навигация по истории: клавиши Up/Down

### 4.6. Настройки приложения

* SettingsWindow.swift (SwiftUI)
  * Вкладки: Модели, Персонализация, Горячие клавиши
  * Управление загрузкой/выгрузкой LLM, автоперсонализация, выбор папки документов

* PersonalizationManager.swift
  * `func generatePersonaVector(for documents: [Document]) async -> Data`
  * `func indexTextSegment(_: TextSegment, in document: Document)`
  * `func getRelevantContext(for prompt: String, in document: Document) -> String`

## 5. Важные Технические Заметки

### 5.1. Объяснение Архитектурных Решений

**Управление окнами:** 
- WindowManager координирует между окнами (редактор, настройки, список документов)
- Предотвращает открытие дублирующихся окон
- Передает данные между окнами (например, выбор документа в списке → открытие в редакторе)

**SwiftData vs Файловая система:**
- **SwiftData (SQLite):** Метаданные, история, теги, векторы персонализации - данные, которые нужно искать и фильтровать
- **Файловая система:** Сами документы пользователя (.killah, .txt) - большие файлы, которые пользователь может перемещать
- **Память приложения:** Текущий текст в редакторе, кэши UI

**Теги и персонализация:**
- `TextSegment` связывает участки текста с векторами персонализации
- Позволяет LLM понимать контекст разных частей документа
- Автоматически создается при работе с LLM

### 5.2. Последовательность Разработки

1. **Сначала базовый редактор** - без этого нельзя тестировать остальное
2. **Потом каретка** - самая сложная часть, требует итерации и тестирования  
3. **Затем управление документами** - когда есть что сохранять
4. **Голосовой ввод** - дополнительная фича
5. **Полировка** - когда все работает

### 5.3. Распределение по Неделям vs Этапам

- **Недели 1-2:** Этап 1 (базовый редактор) + начало Этапа 2 (каретка)
- **Недели 2-3:** Завершение Этапа 2 (каретка) + начало Этапа 3 (документы)  
- **Недели 3-4:** Этап 3 (документы) + Этап 4 (голос)
- **Недели 5-6:** Этап 5 (полировка) + интеграция финальных LLM моделей
